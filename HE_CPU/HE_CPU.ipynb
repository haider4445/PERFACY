{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passive-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "from time import time, process_time\n",
    "import pickle\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import sys\n",
    "#from pympler import asizeof\n",
    "import statistics\n",
    "@dataclass\n",
    "class Results:\n",
    "    \"\"\"Class for keeping track of an item in inventory.\"\"\"\n",
    "    time: float\n",
    "    value: Any\n",
    "    shapes: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divided-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def encrypt(weights, context):\n",
    "    start = process_time()\n",
    "    res = {}\n",
    "    shapes = {}\n",
    "    # Do encryption\n",
    "    for key in weights.keys():\n",
    "        v1 = weights[key]\n",
    "        shapes[key] = v1.shape\n",
    "        v1 = v1.view(-1)\n",
    "        if len(v1) > 8192//2:\n",
    "            vals = chunks(v1, 8192//2)\n",
    "            broken = []\n",
    "            for chunk in vals:\n",
    "                broken.append(ts.ckks_vector(context, chunk))\n",
    "            res[key] = broken\n",
    "        else:\n",
    "            res[key]= ts.ckks_vector(context, v1)\n",
    "    stop = process_time()\n",
    "    return Results(stop-start, res, shapes)\n",
    "\n",
    "\n",
    "def encrypt_n(weights, context, n):\n",
    "    start = process_time()\n",
    "    res = {}\n",
    "    shapes = {}\n",
    "    # Do encryption\n",
    "    for key in weights.keys():\n",
    "        v1 = weights[key]\n",
    "        shapes[key] = v1.shape\n",
    "        v1 = v1.view(-1)\n",
    "        if len(v1) > n//2:\n",
    "            vals = chunks(v1, n//2)\n",
    "            broken = []\n",
    "            for chunk in vals:\n",
    "                broken.append(ts.ckks_vector(context, chunk))\n",
    "            res[key] = broken\n",
    "        else:\n",
    "            res[key]= ts.ckks_vector(context, v1)\n",
    "    stop = process_time()\n",
    "    return Results(stop-start, res, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unlimited-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt(weights, shapes:Dict):\n",
    "    start = process_time()\n",
    "    res = {}\n",
    "    # Do deencryption\n",
    "    for key in weights:\n",
    "        if isinstance(weights[key], list):\n",
    "            lst = []\n",
    "            for val in weights[key]:\n",
    "                lst.extend(val.decrypt())\n",
    "            res[key] = torch.Tensor(lst).view(shapes[key])\n",
    "                \n",
    "        else:\n",
    "            res[key] = torch.Tensor(weights[key].decrypt())\n",
    "    stop = process_time()\n",
    "    return Results(stop-start, res, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import humanize\n",
    "\n",
    "def get_human_readable_bytes(byte_count):\n",
    "    return humanize.naturalsize(byte_count)\n",
    "\n",
    "def fsize(stuff, shapes)->int:\n",
    "    \"\"\" The file size in bytes\"\"\"\n",
    "    bytes_s = 0\n",
    "    for val in stuff:\n",
    "        if isinstance(stuff[val], ts.tensors.ckksvector.CKKSVector):\n",
    "            proto = stuff[val].serialize()\n",
    "            pickle_data = pickle.dumps(proto)\n",
    "            bytes_s += len(pickle_data)\n",
    "        else:\n",
    "            for item in stuff[val]:\n",
    "                proto = item.serialize()\n",
    "                pickle_data = pickle.dumps(proto)\n",
    "                bytes_s += len(pickle_data)\n",
    "    return get_human_readable_bytes(len(pickle.dumps(shapes)) + bytes_s)\n",
    "\n",
    "\n",
    "def fsize2(stuff)->int:\n",
    "    \"\"\" The file size in bytes\"\"\"\n",
    "    bytes_s = 0\n",
    "    for val in stuff:\n",
    "        if isinstance(stuff[val], ts.tensors.ckksvector.CKKSVector):\n",
    "            proto = stuff[val].serialize()\n",
    "            print(type(proto))\n",
    "            bytes_s += len(proto)\n",
    "        else:\n",
    "            for item in stuff[val]:\n",
    "                proto = item.serialize()\n",
    "                bytes_s += len(proto)\n",
    "    return bytes_s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharp-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(fname: str, model: Dict[str, Any]) -> int:\n",
    "    with open(fname, \"wb\") as fptr:\n",
    "        with io.BytesIO() as buff:\n",
    "            pickle.dump(model, buff)\n",
    "            buff.seek(0)\n",
    "            size = buff.getbuffer().nbytes\n",
    "            fptr.write((size).to_bytes(32, byteorder=\"big\", signed=False))\n",
    "            buff.seek(0)\n",
    "            fptr.write(buff.getbuffer())\n",
    "    return 32 + size\n",
    "\n",
    "def read_model(fname)->Dict[str, Any]:\n",
    "    with open(fname, \"rb\") as fptr:\n",
    "        fptr.seek(32)\n",
    "        data = pickle.load(fptr)\n",
    "    return data\n",
    "\n",
    "def get_model():\n",
    "    return read_model(\"./data.pickle\")\n",
    "\n",
    "x=get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=32768,\n",
    "            coeff_mod_bit_sizes=[60, 60, 60, 60,60]\n",
    "          )\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greater-negotiation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 9216])\n",
      "===\n",
      "1179648\n",
      "16384\n",
      "---\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n",
      "<tenseal.tensors.ckksvector.CKKSVector object at 0x2b2234cef850>\n"
     ]
    }
   ],
   "source": [
    "v1 = x[list(x.keys())[0]]\n",
    "v1 = x[\"fc1.weight\"]\n",
    "shape = v1.shape\n",
    "print(shape)\n",
    "v1 = v1.view(-1)\n",
    "print(\"===\")\n",
    "print(len(v1))\n",
    "print(len(v1[:32768//2]))\n",
    "v1 = v1[:32768//2]\n",
    "print(\"---\")\n",
    "v1 = v1.tolist()\n",
    "print(x.keys())\n",
    "enc_v1 = ts.ckks_vector(context, v1)\n",
    "print(enc_v1)\n",
    "#result = enc_v1 + enc_v2\n",
    "#result.decrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptimes_e = []\n",
    "ptimes_d = []\n",
    "sizes = []\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[40, 21, 21, 21, 21, 21, 21, 40]\n",
    "          )\n",
    " \n",
    "    context.generate_galois_keys()\n",
    "    context.global_scale = 2**20\n",
    "    x=get_model()\n",
    "\n",
    "    res = encrypt(x, context) \n",
    "    ptimes_e.append(res.time)\n",
    "    sizes.append( fsize2(res.value))\n",
    "\n",
    "    #print(f\"Encrypt Time {res.time}\")\n",
    "    #print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "    res = decrypt(res.value, res.shapes)\n",
    "    ptimes_d.append(res.time)\n",
    "    #print(f\"Decrypt Time {res.time}\")\n",
    "    \n",
    "print(\"encrypt\", statistics.fmean(ptimes_e))\n",
    "print(\"decrypt\", statistics.fmean(ptimes_d))\n",
    "print(\"sizes\", statistics.fmean(sizes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptimes_e = []\n",
    "ptimes_d = []\n",
    "sizes = []\n",
    "\n",
    "for _ in range(100):\n",
    "    context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[40, 21, 21, 21, 40]\n",
    "          )\n",
    " \n",
    "    context.generate_galois_keys()\n",
    "    context.global_scale = 2**20\n",
    "    x=get_model()\n",
    "\n",
    "    res = encrypt(x, context) \n",
    "    ptimes_e.append(res.time)\n",
    "    #print(f\"Encrypt Time {res.time}\")\n",
    "    sizes.append(fsize2(res.value))\n",
    "    res = decrypt(res.value, res.shapes)\n",
    "    ptimes_d.append(res.time)\n",
    "    #print(f\"Decrypt Time {res.time}\")\n",
    "    \n",
    "print(\"encrypt\", statistics.fmean(ptimes_e))\n",
    "print(\"decrypt\", statistics.fmean(ptimes_d))\n",
    "print(\"sizes\", statistics.fmean(sizes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptimes_e = []\n",
    "ptimes_d = []\n",
    "sizes = []\n",
    "\n",
    "\n",
    "for _ in range(100):\n",
    "    context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[40, 21, 40]\n",
    "          )\n",
    " \n",
    "    context.generate_galois_keys()\n",
    "    context.global_scale = 2**20\n",
    "    x=get_model()\n",
    "\n",
    "    res = encrypt(x, context) \n",
    "    ptimes_e.append(res.time)\n",
    "    sizes.append(fsize2(res.value))\n",
    "\n",
    "    #print(f\"Encrypt Time {res.time}\")\n",
    "    #print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "    res = decrypt(res.value, res.shapes)\n",
    "    ptimes_d.append(res.time)\n",
    "    #print(f\"Decrypt Time {res.time}\")\n",
    "    \n",
    "print(\"encrypt\", statistics.fmean(ptimes_e))\n",
    "print(\"decrypt\", statistics.fmean(ptimes_d))\n",
    "print(\"sizes\", statistics.fmean(sizes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[40, 21, 21, 21, 40]\n",
    "          )\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**20\n",
    "x=get_model()\n",
    "\n",
    "res = encrypt(x, context)\n",
    "print(f\"Encrypt Time {res.time}\")\n",
    "print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "res = decrypt(res.value, res.shapes)\n",
    "print(f\"Decrypt Time {res.time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[40, 21, 40]\n",
    "          )\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**20\n",
    "x=get_model()\n",
    "\n",
    "res = encrypt(x, context)\n",
    "print(f\"Encrypt Time {res.time}\")\n",
    "print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "res = decrypt(res.value, res.shapes)\n",
    "print(f\"Decrypt Time {res.time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[60, 60, 60]\n",
    "          )\n",
    " \n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**20\n",
    "x=get_model()\n",
    "\n",
    "res = encrypt(x, context)\n",
    "print(f\"Encrypt Time {res.time}\")\n",
    "print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "res = decrypt(res.value, res.shapes)\n",
    "print(f\"Decrypt Time {res.time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[40, 40, 40]\n",
    "          )\n",
    " \n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**20\n",
    "x=get_model()\n",
    "\n",
    "res = encrypt(x, context)\n",
    "print(f\"Encrypt Time {res.time}\")\n",
    "print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "res = decrypt(res.value, res.shapes)\n",
    "print(f\"Decrypt Time {res.time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[20, 20, 20]\n",
    "          )\n",
    " \n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**20\n",
    "x=get_model()\n",
    "\n",
    "res = encrypt(x, context)\n",
    "print(f\"Encrypt Time {res.time}\")\n",
    "print(f\"Encrypt size {fsize(res.value, res.shapes)}\")\n",
    "res = decrypt(res.value, res.shapes)\n",
    "print(f\"Decrypt Time {res.time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [8192, 16384, 32768]:\n",
    "    ptimes_e = []\n",
    "    ptimes_d = []\n",
    "    sizes=[]\n",
    "    for _ in range(100):\n",
    "        context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=n,\n",
    "            coeff_mod_bit_sizes=[40, 40, 40]\n",
    "          )\n",
    " \n",
    "        context.generate_galois_keys()\n",
    "        context.global_scale = 2**20\n",
    "        x=get_model()\n",
    "\n",
    "        res = encrypt_n(x, context, n) \n",
    "        ptimes_e.append(res.time)\n",
    "        sizes.append(fsize2(res.value))\n",
    "        res = decrypt(res.value, res.shapes)\n",
    "        ptimes_d.append(res.time)\n",
    "    \n",
    "    print(f\"{n:>6} encrypt\", statistics.fmean(ptimes_e))\n",
    "    print(f\"{n:>6} decrypt\", statistics.fmean(ptimes_d)) \n",
    "    print(f\"{n:>6} size\", statistics.fmean(sizes)) \n",
    "\n",
    "    print(\"-\"*45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-chance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (my_tensorflow_env_fedlab)",
   "language": "python",
   "name": "my_tensorflow_env_fedlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
